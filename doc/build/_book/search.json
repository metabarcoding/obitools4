[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OBITools V4",
    "section": "",
    "text": "Preface\nThe first version of OBITools started to be developed in 2005. This was at the beginning of the DNA metabarcoding story at the Laboratoire d’Ecologie Alpine (LECA) in Grenoble. At that time, with Pierre Taberlet and François Pompanon, we were thinking about the potential of this new methodology under development. PIerre and François developed more the laboratory methods, while I was thinking more about the tools for analysing the sequences produced. Two ideas were behind this development. I wanted something modular, and something easy to extend. To achieve the first goal, I decided to implement obitools as a suite of unix commands mimicking the classic unix commands but dedicated to sequence files. The basic unix commands are very useful for automatically manipulating, parsing and editing text files. They work in flow, line by line on the input text. The result is a new text file that can be used as input for the next command. Such a design makes it possible to quickly develop a text processing pipeline by chaining simple elementary operations. The OBITools are the exact counterpart of these basic Unix commands, but the basic information they process is a sequence (potentially spanning several lines of text), not a single line of text. Most OBITools consume sequence files and produce sequence files. Thus, the principles of chaining and modularity are respected. In order to be able to easily extend the OBITools to keep up with our evolving ideas about processing DNA metabarcoding data, it was decided to develop them using an interpreted language: Python. Python 2, the version available at the time, allowed us to develop the OBITools efficiently. When parts of the algorithms were computationally demanding, they were implemented in C and linked to the Python code. Even though Python is not the most efficient language available, even though computers were not as powerful as they are today, the size of the data we could produce using 454 sequencers or early solexa machines was small enough to be processed in a reasonable time.\nThe first public version of obitools was OBITools2 (Boyer et al. 2016), this was actually a cleaned up and documented version of OBITools that had been running at LECA for years and was not really distributed except to a few collaborators. This is where OBITools started its public life from then on. The DNA metabarcoding spring schools provided and still provide user training every year. But OBITools2 soon suffered from two limitations: it was developed in Python2, which was increasingly abandoned in favour of Python3, and the data size kept increasing with the new illumina machines. Python’s intrinsic slowness coupled with the increasing size of the datasets made OBITools computation times increasingly long. The abandonment of all maintenance of Python2 by its developers also imposed the need for a new version of OBITools.\nOBITools3 was the first response to this crisis. Developed and maintained by Céline Mercier, OBITools3 attempted to address several limitations of OBITools2. It is a complete new code, mainly developed in Python3, with most of the lower layer code written in C for efficiency. OBITools3 has also abandoned text files for binary files for the same reason of efficiency. They have been replaced by a database structure that keeps track of every operation performed on the data.\nHere we present OBITools4 which can be seen as a return to the origins of OBITools. While OBITools3 offered traceability of analyses, which is in line with the concept of open science, and faster execution, OBITools2 was more versatile and not only usable for the analysis of DNA metabarcoding data. OBITools4 is the third full implementation of OBITools. The idea behind this new version is to go back to the original design of OBITools which ran on text files containing sequences, like the classic Unix commands, but running at least as fast as OBITools3 and taking advantage of the multicore architecture of all modern laptops. For this, the idea of relying on an interpreted language was abandoned. The OBITools4 are now fully implemented in the GO language with the exception of a few small pieces of specific code already implemented very efficiently in C. OBITools4 also implement a new format for the annotations inserted in the header of every sequences. Rather tha relying on a format specific to OBITools, by default OBITools4 use the JSON format. This simplifies the writing of parsers in any languages, and thus allows obitools to easiestly interact with other software.\n\n\n\n\nBoyer, Frédéric, Céline Mercier, Aurélie Bonin, Yvan Le Bras, Pierre Taberlet, and Eric Coissac. 2016. “obitools: a unix-inspired software package for DNA metabarcoding.” Molecular Ecology Resources 16 (1): 176–82. https://doi.org/10.1111/1755-0998.12428."
  },
  {
    "objectID": "intro.html#aims-of-obitools",
    "href": "intro.html#aims-of-obitools",
    "title": "The OBITools",
    "section": "Aims of OBITools",
    "text": "Aims of OBITools\nDNA metabarcoding is an efficient approach for biodiversity studies (Taberlet et al. 2012). Originally mainly developed by microbiologists (e.g. Sogin et al. 2006), it is now widely used for plants (e.g. Sønstebø et al. 2010; Yoccoz et al. 2012; Parducci et al. 2012) and animals from meiofauna (e.g. Chariton et al. 2010; Baldwin et al. 2013) to larger organisms (e.g. Andersen et al. 2012; Thomsen et al. 2012). Interestingly, this method is not limited to sensu stricto biodiversity surveys, but it can also be implemented in other ecological contexts such as for herbivore (e.g. Valentini et al. 2009; Kowalczyk et al. 2011) or carnivore (e.g. Deagle, Kirkwood, and Jarman 2009; Shehzad et al. 2012) diet analyses.\nWhatever the biological question under consideration, the DNA metabarcoding methodology relies heavily on next-generation sequencing (NGS), and generates considerable numbers of DNA sequence reads (typically million of reads). Manipulation of such large datasets requires dedicated programs usually running on a Unix system. Unix is an operating system, whose first version was created during the sixties. Since its early stages, it is dedicated to scientific computing and includes a large set of simple tools to efficiently process text files. Most of those programs can be viewed as filters extracting information from a text file to create a new text file. These programs process text files as streams, line per line, therefore allowing computation on a huge dataset without requiring a large memory. Unix programs usually print their results to their standard output (stdout), which by default is the terminal, so the results can be examined on screen. The main philosophy of the Unix environment is to allow easy redirection of the stdout either to a file, for saving the results, or to the standard input (stdin) of a second program thus allowing to easily create complex processing from simple base commands. Access to Unix computers is increasingly easier for scientists nowadays. Indeed, the Linux operating system, an open source version of Unix, can be freely installed on every PC machine and the MacOS operating system, running on Apple computers, is also a Unix system. The OBITools programs imitate Unix standard programs because they usually act as filters, reading their data from text files or the stdin and writing their results to the stdout. The main difference with classical Unix programs is that text files are not analyzed line per line but sequence record per sequence record (see below for a detailed description of a sequence record). Compared to packages for similar purposes like mothur (Schloss et al. 2009) or QIIME (Caporaso et al. 2010), the OBITools mainly rely on filtering and sorting algorithms. This allows users to set up versatile data analysis pipelines (Figure 1), adjustable to the broad range of DNA metabarcoding applications. The innovation of the OBITools is their ability to take into account the taxonomic annotations, ultimately allowing sorting and filtering of sequence records based on the taxonomy.\n\n\n\n\nAndersen, Kenneth, Karen Lise Bird, Morten Rasmussen, James Haile, Henrik Breuning-Madsen, Kurt H Kjaer, Ludovic Orlando, M Thomas P Gilbert, and Eske Willerslev. 2012. “Meta-barcoding of ëdirtı́DNA from soil reflects vertebrate biodiversity.” Molecular Ecology 21 (8): 1966–79.\n\n\nBaldwin, Darren S, Matthew J Colloff, Gavin N Rees, Anthony A Chariton, Garth O Watson, Leon N Court, Diana M Hartley, et al. 2013. “Impacts of inundation and drought on eukaryote biodiversity in semi-arid floodplain soils.” Molecular Ecology 22 (6): 1746–58. https://doi.org/10.1111/mec.12190.\n\n\nCaporaso, J Gregory, Justin Kuczynski, Jesse Stombaugh, Kyle Bittinger, Frederic D Bushman, Elizabeth K Costello, Noah Fierer, et al. 2010. “QIIME allows analysis of high-throughput community sequencing data.” Nature Methods 7 (5): 335–36. https://doi.org/10.1038/nmeth.f.303.\n\n\nChariton, Anthony A, Anthony C Roach, Stuart L Simpson, and Graeme E Batley. 2010. “Influence of the choice of physical and chemistry variables on interpreting patterns of sediment contaminants and their relationships with estuarine macrobenthic communities.” Marine and Freshwater Research. https://doi.org/10.1071/mf09263.\n\n\nDeagle, Bruce E, Roger Kirkwood, and Simon N Jarman. 2009. “Analysis of Australian fur seal diet by pyrosequencing prey DNA in faeces.” Molecular Ecology 18 (9): 2022–38. https://doi.org/10.1111/j.1365-294X.2009.04158.x.\n\n\nKowalczyk, Rafał, Pierre Taberlet, Eric Coissac, Alice Valentini, Christian Miquel, Tomasz Kamiński, and Jan M Wójcik. 2011. “Influence of management practices on large herbivore diet—Case of European bison in Białowieża Primeval Forest (Poland).” Forest Ecology and Management 261 (4): 821–28. https://doi.org/10.1016/j.foreco.2010.11.026.\n\n\nParducci, Laura, Tina Jørgensen, Mari Mette Tollefsrud, Ellen Elverland, Torbjørn Alm, Sonia L Fontana, K D Bennett, et al. 2012. “Glacial survival of boreal trees in northern Scandinavia.” Science 335 (6072): 1083–86. https://doi.org/10.1126/science.1216043.\n\n\nSchloss, Patrick D, Sarah L Westcott, Thomas Ryabin, Justine R Hall, Martin Hartmann, Emily B Hollister, Ryan A Lesniewski, et al. 2009. “Introducing mothur: open-source, platform-independent, community-supported software for describing and comparing microbial communities.” Applied and Environmental Microbiology 75 (23): 7537–41. https://doi.org/10.1128/AEM.01541-09.\n\n\nShehzad, Wasim, Tiayyba Riaz, Muhammad A Nawaz, Christian Miquel, Carole Poillot, Safdar A Shah, Francois Pompanon, Eric Coissac, and Pierre Taberlet. 2012. “Carnivore diet analysis based on next-generation sequencing: Application to the leopard cat (Prionailurus bengalensis) in Pakistan.” Molecular Ecology 21 (8): 1951–65. https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-294X.2011.05424.x.\n\n\nSogin, Mitchell L, Hilary G Morrison, Julie A Huber, David Mark Welch, Susan M Huse, Phillip R Neal, Jesus M Arrieta, and Gerhard J Herndl. 2006. “Microbial diversity in the deep sea and the underexplored \"rare biosphere\".” Proceedings of the National Academy of Sciences of the United States of America 103 (32): 12115–20. https://doi.org/10.1073/pnas.0605127103.\n\n\nSønstebø, J H, L Gielly, A K Brysting, R Elven, M Edwards, J Haile, E Willerslev, et al. 2010. “Using next-generation sequencing for molecular reconstruction of past Arctic vegetation and climate.” Molecular Ecology Resources 10 (6): 1009–18. https://doi.org/10.1111/j.1755-0998.2010.02855.x.\n\n\nTaberlet, Pierre, Eric Coissac, Mehrdad Hajibabaei, and Loren H Rieseberg. 2012. “Environmental DNA.” Molecular Ecology 21 (8): 1789–93. https://doi.org/10.1111/j.1365-294X.2012.05542.x.\n\n\nThomsen, Philip Francis, Jos Kielgast, Lars L Iversen, Carsten Wiuf, Morten Rasmussen, M Thomas P Gilbert, Ludovic Orlando, and Eske Willerslev. 2012. “Monitoring endangered freshwater biodiversity using environmental DNA.” Molecular Ecology 21 (11): 2565–73. https://doi.org/10.1111/j.1365-294X.2011.05418.x.\n\n\nValentini, Alice, Christian Miquel, Muhammad Ali Nawaz, Eva Bellemain, Eric Coissac, François Pompanon, Ludovic Gielly, et al. 2009. “New perspectives in diet analysis based on DNA barcoding and parallel pyrosequencing: the trnL approach.” Molecular Ecology Resources 9 (1): 51–60. https://doi.org/10.1111/j.1755-0998.2008.02352.x.\n\n\nYoccoz, N G, K A Bråthen, L Gielly, J Haile, M E Edwards, T Goslar, H Von Stedingk, et al. 2012. “DNA from soil mirrors plant taxonomic and growth form diversity.” Molecular Ecology 21 (15): 3647–55. https://doi.org/10.1111/j.1365-294X.2012.05545.x."
  },
  {
    "objectID": "installation.html#availability-of-the-obitools",
    "href": "installation.html#availability-of-the-obitools",
    "title": "1  Installation of the obitools",
    "section": "1.1 Availability of the OBITools",
    "text": "1.1 Availability of the OBITools\nThe OBITools are open source and protected by the CeCILL 2.1 license.\nAll the sources of the OBITools4 can be downloaded from the metabarcoding git server (https://git.metabarcoding.org)."
  },
  {
    "objectID": "installation.html#prerequisites",
    "href": "installation.html#prerequisites",
    "title": "1  Installation of the obitools",
    "section": "1.2 Prerequisites",
    "text": "1.2 Prerequisites\nThe OBITools4 are developped using the GO programming language, we stick to the latest version of the language, today the \\(1.19.5\\). If you want to download and compile the sources yourself, you first need to install the corresponding compiler on your system. Some parts of the soft are also written in C, therefore a recent C compiler is also requested, GCC on Linux or Windows, the Developer Tools on Mac.\nWhatever the installation you decide for, you will have to ensure that a C compiler is available on your system."
  },
  {
    "objectID": "installation.html#installation-with-the-install-script",
    "href": "installation.html#installation-with-the-install-script",
    "title": "1  Installation of the obitools",
    "section": "1.3 Installation with the install script",
    "text": "1.3 Installation with the install script"
  },
  {
    "objectID": "installation.html#compilation-from-sources",
    "href": "installation.html#compilation-from-sources",
    "title": "1  Installation of the obitools",
    "section": "1.4 Compilation from sources",
    "text": "1.4 Compilation from sources"
  },
  {
    "objectID": "formats.html",
    "href": "formats.html",
    "title": "2  File formats usable with OBITools",
    "section": "",
    "text": "3 The DNA sequence data\nSequences can be stored following various format. OBITools knows some of them. The central formats for sequence files manipulated by OBITools scripts are the fasta and fastq format. OBITools extends the both these formats by specifying a syntax to include in the definition line data qualifying the sequence. All file formats use the IUPAC code for encoding nucleotides.\nMoreover these two formats that can be used as input and output formats, OBITools4 can read the following format :"
  },
  {
    "objectID": "formats.html#the-iupac-code",
    "href": "formats.html#the-iupac-code",
    "title": "2  File formats usable with OBITools",
    "section": "3.1 The IUPAC Code",
    "text": "3.1 The IUPAC Code\nThe International Union of Pure and Applied Chemistry (IUPAC_) defined the standard code for representing protein or DNA sequences.\n\n\n\nCode\nNucleotide\n\n\n\n\nA\nAdenine\n\n\nC\nCytosine\n\n\nG\nGuanine\n\n\nT\nThymine\n\n\nU\nUracil\n\n\nR\nPurine (A or G)\n\n\nY\nPyrimidine (C, T, or U)\n\n\nM\nC or A\n\n\nK\nT, U, or G\n\n\nW\nT, U, or A\n\n\nS\nC or G\n\n\nB\nC, T, U, or G (not A)\n\n\nD\nA, T, U, or G (not C)\n\n\nH\nA, T, U, or C (not G)\n\n\nV\nA, C, or G (not T, not U)\n\n\nN\nAny base (A, C, G, T, or U)"
  },
  {
    "objectID": "formats.html#sec-fasta",
    "href": "formats.html#sec-fasta",
    "title": "2  File formats usable with OBITools",
    "section": "3.2 The fasta sequence format",
    "text": "3.2 The fasta sequence format\nThe fasta format is certainly the most widely used sequence file format. This is certainly due to its great simplicity. It was originally created for the Lipman and Pearson FASTA program. OBITools use in more of the classical fasta format an extended version of this format where structured data are included in the title line.\nIn fasta format a sequence is represented by a title line beginning with a > character and the sequences by itself following the :doc:iupac code. The sequence is usually split other severals lines of the same length (expect for the last one)\n>my_sequence this is my pretty sequence\nACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGT\nGTGCTGACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTGTTT\nAACGACGTTGCAGTACGTTGCAGT\nThis is no special format for the title line excepting that this line should be unique. Usually the first word following the > character is considered as the sequence identifier. The end of the title line corresponding to a description of the sequence. Several sequences can be concatenated in a same file. The description of the next sequence is just pasted at the end of the record of the previous one\n>sequence_A this is my first pretty sequence\nACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGT\nGTGCTGACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTGTTT\nAACGACGTTGCAGTACGTTGCAGT\n>sequence_B this is my second pretty sequence\nACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGT\nGTGCTGACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTGTTT\nAACGACGTTGCAGTACGTTGCAGT\n>sequence_C this is my third pretty sequence\nACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGT\nGTGCTGACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTACGTTGCAGTGTTT\nAACGACGTTGCAGTACGTTGCAGT"
  },
  {
    "objectID": "formats.html#sec-fastq",
    "href": "formats.html#sec-fastq",
    "title": "2  File formats usable with OBITools",
    "section": "3.3 The fastq sequence format1",
    "text": "3.3 The fastq sequence format1\nThe FASTQ format is a text file format for storing both biological sequences (only nucleic acid sequences) and the associated quality scores. The sequence and score are each encoded by a single ASCII character. This format was originally developed by the Wellcome Trust Sanger Institute to link a FASTA sequence file to the corresponding quality data, but has recently become the de facto standard for storing results from high-throughput sequencers (Cock et al. 2010).\nA fastq file normally uses four lines per sequence.\n\nLine 1 begins with a ‘@’ character and is followed by a sequence identifier and an optional description (like a :ref:fasta title line).\nLine 2 is the raw sequence letters.\nLine 3 begins with a ‘+’ character and is optionally followed by the same sequence identifier (and any description) again.\nLine 4 encodes the quality values for the sequence in Line 2, and must contain the same number of symbols as letters in the sequence.\n\nA fastq file containing a single sequence might look like this:\n@SEQ_ID\nGATTTGGGGTTCAAAGCAGTATCGATCAAATAGTAAATCCATTTGTTCAACTCACAGTTT\n+\n!''*((((***+))%%%++)(%%%%).1***-+*''))**55CCF>>>>>>CCCCCCC65\nThe character ‘!’ represents the lowest quality while ‘~’ is the highest. Here are the quality value characters in left-to-right increasing order of quality (ASCII):\n!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]\n^_`abcdefghijklmnopqrstuvwxyz{|}~\nThe original Sanger FASTQ files also allowed the sequence and quality strings to be wrapped (split over multiple lines), but this is generally discouraged as it can make parsing complicated due to the unfortunate choice of “@” and “+” as markers (these characters can also occur in the quality string).\n\nSequence quality scores\nThe Phred quality value Q is an integer mapping of p (i.e., the probability that the corresponding base call is incorrect). Two different equations have been in use. The first is the standard Sanger variant to assess reliability of a base call, otherwise known as Phred quality score:\n\\[\nQ_\\text{sanger} = -10 \\, \\log_{10} p\n\\]\nThe Solexa pipeline (i.e., the software delivered with the Illumina Genome Analyzer) earlier used a different mapping, encoding the odds \\(\\mathbf{p}/(1-\\mathbf{p})\\) instead of the probability \\(\\mathbf{p}\\):\n\\[\nQ_\\text{solexa-prior to v.1.3} = -10 \\; \\log_{10} \\frac{p}{1-p}\n\\]\nAlthough both mappings are asymptotically identical at higher quality values, they differ at lower quality levels (i.e., approximately \\(\\mathbf{p} > 0.05\\), or equivalently, \\(\\mathbf{Q} < 13\\)).\n\n\n\nFigure 3.1: Relationship between Q and p using the Sanger (red) and Solexa (black) equations (described above). The vertical dotted line indicates \\(\\mathbf{p}= 0.05\\), or equivalently, \\(Q = 13\\).\n\n\n\nEncoding\nThe fastq format had differente way of encoding the Phred quality score along the time. Here a breif history of these changes is presented.\n\nSanger format can encode a Phred quality score from 0 to 93 using ASCII 33 to 126 (although in raw read data the Phred quality score rarely exceeds 60, higher scores are possible in assemblies or read maps).\nSolexa/Illumina 1.0 format can encode a Solexa/Illumina quality score from -5 to 62 using ASCII 59 to 126 (although in raw read data Solexa scores from -5 to 40 only are expected)\nStarting with Illumina 1.3 and before Illumina 1.8, the format encoded a Phred quality score from 0 to 62 using ASCII 64 to 126 (although in raw read data Phred scores from 0 to 40 only are expected).\nStarting in Illumina 1.5 and before Illumina 1.8, the Phred scores 0 to 2 have a slightly different meaning. The values 0 and 1 are no longer used and the value 2, encoded by ASCII 66 “B”.\n\n\nSequencing Control Software, Version 2.6, (Catalog # SY-960-2601, Part # 15009921 Rev. A, November 2009, page 30) states the following: If a read ends with a segment of mostly low quality (Q15 or below), then all of the quality values in the segment are replaced with a value of 2 (encoded as the letter B in Illumina’s text-based encoding of quality scores)… This Q2 indicator does not predict a specific error rate, but rather indicates that a specific final portion of the read should not be used in further analyses. Also, the quality score encoded as “B” letter may occur internally within reads at least as late as pipeline version 1.6, as shown in the following example:\n\n@HWI-EAS209_0006_FC706VJ:5:58:5894:21141#ATCACG/1\nTTAATTGGTAAATAAATCTCCTAATAGCTTAGATNTTACCTTNNNNNNNNNNTAGTTTCTTGAGA\nTTTGTTGGGGGAGACATTTTTGTGATTGCCTTGAT\n+HWI-EAS209_0006_FC706VJ:5:58:5894:21141#ATCACG/1\nefcfffffcfeefffcffffffddf`feed]`]_Ba_^__[YBBBBBBBBBBRTT\\]][ dddd`\nddd^dddadd^BBBBBBBBBBBBBBBBBBBBBBBB\nAn alternative interpretation of this ASCII encoding has been proposed. Also, in Illumina runs using PhiX controls, the character ‘B’ was observed to represent an “unknown quality score”. The error rate of ‘B’ reads was roughly 3 phred scores lower the mean observed score of a given run.\n\nStarting in Illumina 1.8, the quality scores have basically returned to the use of the Sanger format (Phred+33).\n\nOBItools follows the Sanger format. Nevertheless, It is possible to read files encoded following the Solexa/Illumina format by applying a shift of 62 (see the option --solexa of the OBITools commands)."
  },
  {
    "objectID": "formats.html#file-extension",
    "href": "formats.html#file-extension",
    "title": "2  File formats usable with OBITools",
    "section": "3.4 File extension",
    "text": "3.4 File extension\nThere is no standard file extension for a FASTQ file, but .fq and .fastq, are commonly used.\n\n\n\n\nCock, Peter JA, Christopher J Fields, Naohisa Goto, Michael L Heuer, and Peter M Rice. 2010. “The Sanger FASTQ File Format for Sequences with Quality Scores, and the Solexa/Illumina FASTQ Variants.” Nucleic Acids Research 38 (6): 1767–71."
  },
  {
    "objectID": "tutorial.html#wolves-diet-based-on-dna-metabarcoding",
    "href": "tutorial.html#wolves-diet-based-on-dna-metabarcoding",
    "title": "3  OBITools V4 Tutorial",
    "section": "3.1 Wolves’ diet based on DNA metabarcoding",
    "text": "3.1 Wolves’ diet based on DNA metabarcoding\nThe data used in this tutorial correspond to the analysis of four wolf scats, using the protocol published in Shehzad et al. (2012) for assessing carnivore diet. After extracting DNA from the faeces, the DNA amplifications were carried out using the primers TTAGATACCCCACTATGC and TAGAACAGGCTCCTCTAG amplifiying the 12S-V5 region (Riaz et al. 2011), together with a wolf blocking oligonucleotide.\nThe complete data set can be downloaded here: the tutorial dataset\nOnce the data file is downloaded, using a UNIX terminal unarchive the data from the tgz file.\n\ntar zxvf wolf_diet.tgz\n\nThat command create a new directory named wolf_data containing every required data files:\n\nfastq <fastq> files resulting of aGA IIx (Illumina) paired-end (2 x 108 bp) sequencing assay of DNA extracted and amplified from four wolf faeces:\n\nwolf_F.fastq\nwolf_R.fastq\n\nthe file describing the primers and tags used for all samples sequenced:\n\nwolf_diet_ngsfilter.txt The tags correspond to short and specific sequences added on the 5' end of each primer to distinguish the different samples\n\nthe file containing the reference database in a fasta format:\n\ndb_v05_r117.fasta This reference database has been extracted from the release 117 of EMBL using obipcr\n\n\n\n\n\nTo not mix raw data and processed data a new directory called results is created.\n\nmkdir results"
  },
  {
    "objectID": "tutorial.html#step-by-step-analysis",
    "href": "tutorial.html#step-by-step-analysis",
    "title": "3  OBITools V4 Tutorial",
    "section": "3.2 Step by step analysis",
    "text": "3.2 Step by step analysis\n\n3.2.1 Recover full sequence reads from forward and reverse partial reads\nWhen using the result of a paired-end sequencing assay with supposedly overlapping forward and reverse reads, the first step is to recover the assembled sequence.\nThe forward and reverse reads of the same fragment are at the same line position in the two fastq files obtained after sequencing. Based on these two files, the assembly of the forward and reverse reads is done with the obipairing utility that aligns the two reads and returns the reconstructed sequence.\nIn our case, the command is:\n\nobipairing --min-identity=0.8 \\\n           --min-overlap=10 \\\n           -F wolf_data/wolf_F.fastq \\\n           -R wolf_data/wolf_R.fastq \\\n           > results/wolf.fastq \n\nThe --min-identity and --min-overlap options allow discarding sequences with low alignment quality. If after the aligment, the overlaping parts of the reads is shorter than 10 base pairs or the similarity over this aligned region is below 80% of identity, in the output file, the forward and reverse reads are not aligned but concatenated, and the value of the mode attribute in the sequence header is set to joined instead of alignment.\n\n\n3.2.2 Remove unaligned sequence records\nUnaligned sequences (:pymode=joined) cannot be used. The following command allows removing them from the dataset:\n\nobigrep -p 'annotations.mode != \"join\"' \\\n        results/wolf.fastq > results/wolf.ali.fastq\n\nThe -p requires a go like expression. annotations.mode != \"join\" means that if the value of the mode annotation of a sequence is different from join, the corresponding sequence record will be kept.\nThe first sequence record of wolf.ali.fastq can be obtained using the following command line:\n\nhead -n 4 results/wolf.ali.fastq\n\nThe folling piece of code appears on thew window of tour terminal.\n@HELIUM_000100422_612GNAAXX:7:108:5640:3823#0/1 {\"ali_dir\":\"left\",\"ali_length\":62,\"mode\":\"alignment\",\"pairing_mismatches\":{\"(T:26)->(G:13)\":62,\"(T:34)->(G:18)\":48},\"score\":484,\"score_norm\":0.968,\"seq_a_single\":46,\"seq_ab_match\":60,\"seq_b_single\":46}\nccgcctcctttagataccccactatgcttagccctaaacacaagtaattaatataacaaaattgttcgccagagtactaccggcaatagcttaaaactcaaaggacttggcggtgctttatacccttctagaggagcctgttctaaggaggcgg\n+\nCCCCCCCBCCCCCCCCCCCCCCCCCCCCCCBCCCCCBCCCCCCC<CcCccbe[`F`accXV<TA\\RYU\\\\ee_e[XZ[XEEEEEEEEEE?EEEEEEEEEEDEEEEEEECCCCCCCCCCCCCCCCCCCCCCCACCCCCACCCCCCCCCCCCCCCC\n\n\n3.2.3 Assign each sequence record to the corresponding sample/marker combination\nEach sequence record is assigned to its corresponding sample and marker using the data provided in a text file (here wolf_diet_ngsfilter.txt). This text file contains one line per sample, with the name of the experiment (several experiments can be included in the same file), the name of the tags (for example: aattaac if the same tag has been used on each extremity of the PCR products, or aattaac:gaagtag if the tags were different), the sequence of the forward primer, the sequence of the reverse primer, the letter T or F for sample identification using the forward primer and tag only or using both primers and both tags, respectively (see obimultiplex for details).\n\nobimultiplex -t wolf_data/wolf_diet_ngsfilter.txt \\\n             -u results/unidentified.fastq \\\n             results/wolf.ali.fastq \\\n             > results/wolf.ali.assigned.fastq\n\nThis command creates two files:\n\nunidentified.fastq containing all the sequence records that were not assigned to a sample/marker combination\nwolf.ali.assigned.fastq containing all the sequence records that were properly assigned to a sample/marker combination\n\nNote that each sequence record of the wolf.ali.assigned.fastq file contains only the barcode sequence as the sequences of primers and tags are removed by the obimultiplex program. Information concerning the experiment, sample, primers and tags is added as attributes in the sequence header.\nFor instance, the first sequence record of wolf.ali.assigned.fastq is:\n@HELIUM_000100422_612GNAAXX:7:108:5640:3823#0/1_sub[28..127] {\"ali_dir\":\"left\",\"ali_length\":62,\"direction\":\"direct\",\"experiment\":\"wolf_diet\",\"forward_match\":\"ttagataccccactatgc\",\"forward_mismatches\":0,\"forward_primer\":\"ttagataccccactatgc\",\"forward_tag\":\"gcctcct\",\"mode\":\"alignment\",\"pairing_mismatches\":{\"(T:26)->(G:13)\":35,\"(T:34)->(G:18)\":21},\"reverse_match\":\"tagaacaggctcctctag\",\"reverse_mismatches\":0,\"reverse_primer\":\"tagaacaggctcctctag\",\"reverse_tag\":\"gcctcct\",\"sample\":\"29a_F260619\",\"score\":484,\"score_norm\":0.968,\"seq_a_single\":46,\"seq_ab_match\":60,\"seq_b_single\":46}\nttagccctaaacacaagtaattaatataacaaaattgttcgccagagtactaccggcaatagcttaaaactcaaaggacttggcggtgctttataccctt\n+\nCCCBCCCCCBCCCCCCC<CcCccbe[`F`accXV<TA\\RYU\\\\ee_e[XZ[XEEEEEEEEEE?EEEEEEEEEEDEEEEEEECCCCCCCCCCCCCCCCCCC\n\n\n3.2.4 Dereplicate reads into uniq sequences\nThe same DNA molecule can be sequenced several times. In order to reduce both file size and computations time, and to get easier interpretable results, it is convenient to work with unique sequences instead of reads. To dereplicate such reads into unique sequences, we use the obiuniq command.\n\n\n\n\n\n\nDefinition: Dereplicate reads into unique sequences\n\n\n\ncompare all the reads in a data set to each other\ngroup strictly identical reads together\noutput the sequence for each group and its count in the original dataset (in this way, all duplicated reads are removed)\n\nDefinition adapted from Seguritan and Rohwer (2001)\n\n\n\nFor dereplication, we use the obiuniq command with the -m sample. The -m sample option is used to keep the information of the samples of origin for each uniquesequence.\n\nobiuniq -m sample \\\n        results/wolf.ali.assigned.fastq \\\n        > results/wolf.ali.assigned.uniq.fasta\n\nNote that obiuniq returns a fasta file.\nThe first sequence record of wolf.ali.assigned.uniq.fasta is:\n>HELIUM_000100422_612GNAAXX:7:93:6991:1942#0/1_sub[28..126] {\"ali_dir\":\"left\",\"ali_length\":63,\"count\":1,\"direction\":\"reverse\",\"experiment\":\"wolf_diet\",\"forward_match\":\"ttagataccccactatgc\",\"forward_mismatches\":0,\"forward_primer\":\"ttagataccccactatgc\",\"forward_tag\":\"gaatatc\",\"merged_sample\":{\"26a_F040644\":1},\"mode\":\"alignment\",\"pairing_mismatches\":{\"(A:10)->(G:34)\":76,\"(C:06)->(A:34)\":58},\"reverse_match\":\"tagaacaggctcctctag\",\"reverse_mismatches\":0,\"reverse_primer\":\"tagaacaggctcctctag\",\"reverse_tag\":\"gaatatc\",\"score\":730,\"score_norm\":0.968,\"seq_a_single\":45,\"seq_ab_match\":61,\"seq_b_single\":45}\nttagccctaaacataaacattcaataaacaagaatgttcgccagagaactactagcaaca\ngcctgaaactcaaaggacttggcggtgctttatatccct\nThe run of obiuniq has added two key=values entries in the header of the fasta sequence:\n\n\"merged_sample\":{\"29a_F260619\":1}: this sequence have been found once in a single sample called 29a_F260619\n\"count\":1 : the total count for this sequence is \\(1\\)\n\nTo keep only these two attributes, we can use the obiannotate command:\n\nobiannotate -k count -k merged_sample \\\n  results/wolf.ali.assigned.uniq.fasta \\\n  > results/wolf.ali.assigned.simple.fasta\n\nThe first five sequence records of wolf.ali.assigned.simple.fasta become:\n>HELIUM_000100422_612GNAAXX:7:26:18930:11105#0/1_sub[28..127] {\"count\":1,\"merged_sample\":{\"29a_F260619\":1}}\nttagccctaaacacaagtaattaatataacaaaatwattcgcyagagtactacmggcaat\nagctyaaarctcamagrwcttggcggtgctttataccctt\n>HELIUM_000100422_612GNAAXX:7:58:5711:11399#0/1_sub[28..127] {\"count\":1,\"merged_sample\":{\"29a_F260619\":1}}\nttagccctaaacacaagtaattaatataacaaaattattcgccagagtwctaccgssaat\nagcttaaaactcaaaggactgggcggtgctttataccctt\n>HELIUM_000100422_612GNAAXX:7:100:15836:9304#0/1_sub[28..127] {\"count\":1,\"merged_sample\":{\"29a_F260619\":1}}\nttagccctaaacatagataattacacaaacaaaattgttcaccagagtactagcggcaac\nagcttaaaactcaaaggacttggcggtgctttataccctt\n>HELIUM_000100422_612GNAAXX:7:55:13242:9085#0/1_sub[28..126] {\"count\":4,\"merged_sample\":{\"26a_F040644\":4}}\nttagccctaaacataaacattcaataaacaagagtgttcgccagagtactactagcaaca\ngcctgaaactcaaaggacttggcggtgctttacatccct\n>HELIUM_000100422_612GNAAXX:7:86:8429:13723#0/1_sub[28..127] {\"count\":7,\"merged_sample\":{\"15a_F730814\":5,\"29a_F260619\":2}}\nttagccctaaacacaagtaattaatataacaaaattattcgccagagtactaccggcaat\nagcttaaaactcaaaggactcggcggtgctttataccctt\n\n\n3.2.5 Denoise the sequence dataset\nTo have a set of sequences assigned to their corresponding samples does not mean that all sequences are biologically meaningful i.e. some of these sequences can contains PCR and/or sequencing errors, or chimeras.\n\nTag the sequences for PCR errors (sequence variants)\nThe obiclean program tags sequence variants as potential error generated during PCR amplification. We ask it to keep the head sequences (-H option) that are sequences which are not variants of another sequence with a count greater than 5% of their own count (-r 0.05 option).\n\nobiclean -s sample -r 0.05 -H \\\n  results/wolf.ali.assigned.simple.fasta \\\n      > results/wolf.ali.assigned.simple.clean.fasta \n\nOne of the sequence records of wolf.ali.assigned.simple.clean.fasta is:\n>HELIUM_000100422_612GNAAXX:7:66:4039:8016#0/1_sub[28..127] {\"count\":17,\"merged_sample\":{\"13a_F730603\":17},\"obiclean_head\":true,\"obiclean_headcount\":1,\"obiclean_internalcount\":0,\"obi\nclean_samplecount\":1,\"obiclean_singletoncount\":0,\"obiclean_status\":{\"13a_F730603\":\"h\"},\"obiclean_weight\":{\"13a_F730603\":25}}\nctagccttaaacacaaatagttatgcaaacaaaactattcgccagagtactaccggcaac\nagcccaaaactcaaaggacttggcggtgcttcacaccctt\nTo remove such sequences as much as possible, we first discard rare sequences and then rsequence variants that likely correspond to artifacts.\n\n\nGet some statistics about sequence counts\n\nobicount results/wolf.ali.assigned.simple.clean.fasta\n\ntime=\"2023-02-23T18:43:26+01:00\" level=info msg=\"Appending results/wolf.ali.assigned.simple.clean.fasta file\\n\"\n 2749 36409 273387\n\n\nThe dataset contains \\(4313\\) sequences variant corresponding to 42452 sequence reads. Most of the variants occur only a single time in the complete dataset and are usualy named singletons\n\nobigrep -p 'sequence.Count() == 1' results/wolf.ali.assigned.simple.clean.fasta \\\n    | obicount\n\ntime=\"2023-02-23T18:43:26+01:00\" level=info msg=\"Appending results/wolf.ali.assigned.simple.clean.fasta file\\n\"\ntime=\"2023-02-23T18:43:26+01:00\" level=info msg=\"Reading sequences from stdin in guessed\\n\"\ntime=\"2023-02-23T18:43:26+01:00\" level=info msg=\"On output use JSON headers\"\n 2623 2623 261217\n\n\nIn that dataset sigletons corresponds to \\(3511\\) variants.\nUsing R and the ROBIFastread package able to read headers of the fasta files produced by OBITools, we can get more complete statistics on the distribution of occurrencies.\n\nlibrary(ROBIFastread)\nlibrary(ggplot2)\n\nseqs <- read_obifasta(\"results/wolf.ali.assigned.simple.clean.fasta\",keys=\"count\")\n\nggplot(data = seqs,  mapping=aes(x = count)) +\n  geom_histogram(bins=100) +\n  scale_y_sqrt() +\n  scale_x_sqrt() +\n  geom_vline(xintercept = 10, col=\"red\", lty=2) +\n  xlab(\"number of occurrencies of a variant\") \n\n\n\n\nIn a similar way it is also possible to plot the distribution of the sequence length.\n\nggplot(data = seqs,  mapping=aes(x = nchar(sequence))) +\n  geom_histogram() +\n  scale_y_log10() +\n  geom_vline(xintercept = 80, col=\"red\", lty=2) +\n  xlab(\"sequence lengths in base pair\")\n\n\n\n\n\n\nKeep only the sequences having a count greater or equal to 10 and a length shorter than 80 bp\nBased on the previous observation, we set the cut-off for keeping sequences for further analysis to a count of 10. To do this, we use the obigrep <scripts/obigrep> command. The -p 'count>=10' option means that the python expression :pycount>=10 must be evaluated to :pyTrue for each sequence to be kept. Based on previous knowledge we also remove sequences with a length shorter than 80 bp (option -l) as we know that the amplified 12S-V5 barcode for vertebrates must have a length around 100bp.\n\nobigrep -l 80 -p 'sequence.Count() >= 10' results/wolf.ali.assigned.simple.clean.fasta \\\n    > results/wolf.ali.assigned.simple.clean.c10.l80.fasta\n\nThe first sequence record of results/wolf.ali.assigned.simple.clean.c10.l80.fasta is:\n>HELIUM_000100422_612GNAAXX:7:22:2603:18023#0/1_sub[28..127] {\"count\":12182,\"merged_sample\":{\"15a_F730814\":7559,\"29a_F260619\":4623},\"obiclean_head\":true,\"obiclean_headcount\":2,\"obiclean_internalcount\":0,\"obiclean_samplecount\":2,\"obiclean_singletoncount\":0,\"obiclean_status\":{\"15a_F730814\":\"h\",\"29a_F260619\":\"h\"},\"obiclean_weight\":{\"15a_F730814\":9165,\"29a_F260619\":6275}}\nttagccctaaacacaagtaattaatataacaaaattattcgccagagtactaccggcaat\nagcttaaaactcaaaggacttggcggtgctttataccctt\nAt that time in the data cleanning we have conserved :\n\nobicount results/wolf.ali.assigned.simple.clean.c10.l80.fasta\n\ntime=\"2023-02-23T18:43:28+01:00\" level=info msg=\"Appending results/wolf.ali.assigned.simple.clean.c10.l80.fasta file\\n\"\n 26 31337 2585\n\n\n\n\n\n3.2.6 Taxonomic assignment of sequences\nOnce denoising has been done, the next step in diet analysis is to assign the barcodes to the corresponding species in order to get the complete list of species associated to each sample.\nTaxonomic assignment of sequences requires a reference database compiling all possible species to be identified in the sample. Assignment is then done based on sequence comparison between sample sequences and reference sequences.\n\nDownload the taxonomy\nIt is always possible to download the complete taxonomy from NCBI using the following commands.\n\nmkdir TAXO\ncd TAXO\ncurl http://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz \\\n   | tar -zxvf -\ncd ..\n\nFor people have a low speed internet connection, a copy of the taxdump.tar.gz file is provided in the wolf_data directory. The NCBI taxonomy is dayly updated, but the one provided here is ok for running this tutorial.\nTo build the TAXO directory from the provided taxdump.tar.gz, you need to execute the following commands\n\nmkdir TAXO\ncd TAXO\ntar zxvf wolf_data/taxdump.tar.gz \ncd ..\n\n\n\nBuild a reference database\nOne way to build the reference database is to use the obipcr program to simulate a PCR and extract all sequences from a general purpose DNA database such as genbank or EMBL that can be amplified in silico by the two primers (here TTAGATACCCCACTATGC and TAGAACAGGCTCCTCTAG) used for PCR amplification.\nThe two steps to build this reference database would then be\n\nToday, the easiest database to download is Genbank. But this will take you more than a day and occupy more than half a terabyte on your hard drive. In the wolf_data directory, a shell script called download_gb.sh is provided to perform this task. It requires that the programs wget2 and curl are available on your computer.\nUse obipcr to simulate amplification and build a reference database based on the putatively amplified barcodes and their recorded taxonomic information.\n\nAs these steps can take a long time (about a day for the download and an hour for the PCR), we already provide the reference database produced by the following commands so you can skip its construction. Note that as the Genbank and taxonomic database evolve frequently, if you run the following commands you may get different results.\n\nDownload the sequences\n\nmkdir genbank\ncd genbank\n../wolf_data/install_gb.sh\ncd ..\n\nDO NOT RUN THIS COMMAND EXCEPT IF YOU ARE REALLY CONSIENT OF THE TIME AND DISK SPACE REQUIRED.\n\n\nUse obipcr to simulate an in silico` PCR\n\nobipcr -t TAXO -e 3 -l 50 -L 150 \\ \n       --forward TTAGATACCCCACTATGC \\\n       --reverse TAGAACAGGCTCCTCTAG \\\n       --no-order \\\n       genbank/Release-251/gb*.seq.gz\n       > results/v05.pcr.fasta\n\nNote that the primers must be in the same order both in wolf_diet_ngsfilter.txt and in the obipcr command. The part of the path indicating the Genbank release can change. Please check in your genbank directory the exact name of your release.\n\n\nClean the database\n\nfilter sequences so that they have a good taxonomic description at the species, genus, and family levels (obigrep command command below).\nremove redundant sequences (obiuniq command below).\nensure that the dereplicated sequences have a taxid at the family level (obigrep command below).\nensure that sequences each have a unique identification (obiannotate command below)\n\n\nobigrep -t TAXO \\\n          --require-rank species \\\n          --require-rank genus \\\n          --require-rank family \\\n          results/v05.ecopcr > results/v05_clean.fasta\n\nobiuniq -c taxid \\\n        results/v05_clean.fasta \\\n        > results/v05_clean_uniq.fasta\n\nobirefidx -t TAXO results/v05_clean_uniq.fasta \\\n        > results/v05_clean_uniq.indexed.fasta\n\n\n\nWarning\n\nFrom now on, for the sake of clarity, the following commands will use the filenames of the files provided with the tutorial. If you decided to run the last steps and use the files you have produced, you'll have to use results/v05_clean_uniq.indexed.fasta instead of wolf_data/db_v05_r117.indexed.fasta.\n\n\n\n\n\n3.2.7 Assign each sequence to a taxon\nOnce the reference database is built, taxonomic assignment can be carried out using the obitag command.\n\nobitag -t TAXO -R wolf_data/db_v05_r117.indexed.fasta \\\n       results/wolf.ali.assigned.simple.clean.c10.l80.fasta \\\n       > results/wolf.ali.assigned.simple.clean.c10.l80.taxo.fasta\n\nThe obitag adds several attributes in the sequence record header, among them:\n\nobitag_bestmatch=ACCESSION where ACCESSION is the id of hte sequence in the reference database that best aligns to the query sequence;\nobitag_bestid=FLOAT where FLOAT*100 is the percentage of identity between the best match sequence and the query sequence;\ntaxid=TAXID where TAXID is the final assignation of the sequence by obitag\nscientific_name=NAME where NAME is the scientific name of the assigned taxid.\n\nThe first sequence record of wolf.ali.assigned.simple.clean.c10.l80.taxo.fasta is:\n>HELIUM_000100422_612GNAAXX:7:81:18704:12346#0/1_sub[28..126] {\"count\":88,\"merged_sample\":{\"26a_F040644\":88},\"obiclean_head\":true,\"obiclean_headcount\":1,\"obiclean_internalcount\":0,\"obiclean_samplecount\":1,\"obiclean_singletoncount\":0,\"obiclean_status\":{\"26a_F040644\":\"h\"},\"obiclean_weight\":{\"26a_F040644\":208},\"obitag_bestid\":0.9207920792079208,\"obitag_bestmatch\":\"AY769263\",\"obitag_difference\":8,\"obitag_match_count\":1,\"obitag_rank\":\"clade\",\"scientific_name\":\"Boreoeutheria\",\"taxid\":1437010}\nttagccctaaacataaacattcaataaacaagaatgttcgccagaggactactagcaata\ngcttaaaactcaaaggacttggcggtgctttatatccct\n\n\n3.2.8 Generate the final result table\nSome unuseful attributes can be removed at this stage.\n\nobiclean_head\nobiclean_headcount\nobiclean_internalcount\nobiclean_samplecount\nobiclean_singletoncount\n\n\nobiannotate  --delete-tag=obiclean_head \\\n             --delete-tag=obiclean_headcount \\\n             --delete-tag=obiclean_internalcount \\\n             --delete-tag=obiclean_samplecount \\\n             --delete-tag=obiclean_singletoncount \\\n  results/wolf.ali.assigned.simple.clean.c10.l80.taxo.fasta \\\n  > results/wolf.ali.assigned.simple.clean.c10.l80.taxo.ann.fasta\n\nThe first sequence record of wolf.ali.assigned.simple.c10.l80.clean.taxo.ann.fasta is then:\n>HELIUM_000100422_612GNAAXX:7:84:16335:5083#0/1_sub[28..126] {\"count\":96,\"merged_sample\":{\"26a_F040644\":11,\"29a_F260619\":85},\"obiclean_status\":{\"26a_F040644\":\"s\",\"29a_F260619\":\"h\"},\"obiclean_weight\":{\"26a_F040644\":14,\"29a_F260619\":110},\"obitag_bestid\":0.9595959595959596,\"obitag_bestmatch\":\"AC187326\",\"obitag_difference\":4,\"obitag_match_count\":1,\"obitag_rank\":\"subspecies\",\"scientific_name\":\"Canis lupus familiaris\",\"taxid\":9615}\nttagccctaaacataagctattccataacaaaataattcgccagagaactactagcaaca\ngattaaacctcaaaggacttggcagtgctttatacccct\n\n\n3.2.9 Looking at the data in R\n\nlibrary(ROBIFastread)\nlibrary(vegan)\n\nLe chargement a nécessité le package : permute\n\n\nLe chargement a nécessité le package : lattice\n\n\nThis is vegan 2.6-4\n\nlibrary(magrittr)\n \n\ndiet_data <- read_obifasta(\"results/wolf.ali.assigned.simple.clean.c10.l80.taxo.fasta\") \ndiet_data %<>% extract_features(\"obitag_bestmatch\",\"obitag_rank\",\"scientific_name\",'taxid')\n\ndiet_tab <- extract_readcount(diet_data,key=\"obiclean_weight\")\ndiet_tab\n\n4 x 26 sparse Matrix of class \"dgCMatrix\"\n\n\n  [[ suppressing 26 column names 'HELIUM_000100422_612GNAAXX:7:72:17638:8081#0/1_sub[28..126]', 'HELIUM_000100422_612GNAAXX:7:17:3675:13316#0/1_sub[28..126]', 'HELIUM_000100422_612GNAAXX:7:58:11419:17203#0/1_sub[28..126]' ... ]]\n\n\n                                                                             \n26a_F040644 15 17 481  .  .  . 208  .  .  .  .  . 14 31   .    . 43 52  14 72\n13a_F730603  .  .  19  1  . 15   . 22  .  . 20 25  .  .   . 8409  .  .   .  .\n15a_F730814  .  .   5  .  .  .   .  .  .  .  .  .  .  .   .    .  .  .   .  .\n29a_F260619  .  .   1 13 25  .   .  . 16 44  .  .  .  . 391    .  .  . 110  .\n                                  \n26a_F040644 88 18 .   . 12830    .\n13a_F730603  .  . 9   .     .    .\n15a_F730814  .  . 4   .     . 9165\n29a_F260619  .  . . 353     . 5884\n\n\n\nThis file contains 26 sequences. You can deduce the diet of each sample:\n\n\n13a_F730603: Cervus elaphus\n15a_F730814: Capreolus capreolus\n26a_F040644: Marmota sp. (according to the location, it is Marmota marmota)\n29a_F260619: Capreolus capreolus\n\n\n\nNote that we also obtained a few wolf sequences although a wolf-blocking oligonucleotide was used.\n\n\n\n\nRiaz, Tiayyba, Wasim Shehzad, Alain Viari, François Pompanon, Pierre Taberlet, and Eric Coissac. 2011. “ecoPrimers: inference of new DNA barcode markers from whole genome sequence analysis.” Nucleic Acids Research 39 (21): e145. https://doi.org/10.1093/nar/gkr732.\n\n\nSeguritan, V, and F Rohwer. 2001. “FastGroup: a program to dereplicate libraries of 16S rDNA sequences.” BMC Bioinformatics 2 (October): 9. https://doi.org/10.1186/1471-2105-2-9.\n\n\nShehzad, Wasim, Tiayyba Riaz, Muhammad A Nawaz, Christian Miquel, Carole Poillot, Safdar A Shah, Francois Pompanon, Eric Coissac, and Pierre Taberlet. 2012. “Carnivore diet analysis based on next-generation sequencing: Application to the leopard cat (Prionailurus bengalensis) in Pakistan.” Molecular Ecology 21 (8): 1951–65. https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-294X.2011.05424.x."
  },
  {
    "objectID": "inupt.html#specifying-input-format",
    "href": "inupt.html#specifying-input-format",
    "title": "4  Specifying the data input to OBITools commands",
    "section": "4.1 Specifying input format",
    "text": "4.1 Specifying input format\nFive sequence formats are accepted for input files. Fasta (Section 3.2) and Fastq (Section 3.3) are the main ones, EMBL and Genbank allow the use of flat files produced by these two international databases. The last one, ecoPCR, is maintained for compatibility with previous OBITools and allows to read ecoPCR outputs as sequence files.\n\n--ecopcr : Read data following the ecoPCR output format.\n--embl Read data following the EMBL flatfile format.\n--genbank Read data following the Genbank flatfile format.\n\nSeveral encoding schemes have been proposed for quality scores in Fastq format. Currently, OBITools considers Sanger encoding as the standard. For reasons of compatibility with older datasets produced with Solexa sequencers, it is possible, by using the following option, to force the use of the corresponding quality encoding scheme when reading these older files.\n\n--solexa Decodes quality string according to the Solexa specification. (default: false)"
  },
  {
    "objectID": "output.html#specifying-output-format",
    "href": "output.html#specifying-output-format",
    "title": "5  Controling OBITools outputs",
    "section": "5.1 Specifying output format",
    "text": "5.1 Specifying output format\nOnly two output sequence formats are supported by OBITools, Fasta and Fastq. Fastq is used when output sequences are associated with quality information. Otherwise, Fasta is the default format. However, it is possible to force the output format by using one of the following two options. Forcing the use of Fasta results in the loss of quality information. Conversely, when the Fastq format is forced with sequences that have no quality data, dummy qualities set to 40 for each nucleotide are added.\n\n--fasta-output Read data following the ecoPCR output format.\n--fastq-output Read data following the EMBL flatfile format.\n\nOBITools allows multiple input files to be specified for a single command.\n\n--no-order When several input files are provided, indicates that there is no order among them. (default: false). Using such option can increase a lot the processing of the data."
  },
  {
    "objectID": "output.html#the-fasta-and-fastq-annotations-format",
    "href": "output.html#the-fasta-and-fastq-annotations-format",
    "title": "5  Controling OBITools outputs",
    "section": "5.2 The Fasta and Fastq annotations format",
    "text": "5.2 The Fasta and Fastq annotations format\nOBITools extend the Fasta and Fastq formats by introducing a format for the title lines of these formats allowing to annotate every sequence. While the previous version of OBITools used an ad-hoc format for these annotation, this new version introduce the usage of the standard JSON format to store them.\nOn input, OBITools automatically recognize the format of the annotations, but two options allows to force the parsing following one of them. You should normally not need to use these options.\n\n--input-OBI-header FASTA/FASTQ title line annotations follow OBI format. (default: false)\n--input-json-header FASTA/FASTQ title line annotations follow json format. (default: false)\n\nOn output, by default annotation are formatted using the new JSON format. For compatibility with previous version of OBITools and with external scripts and software, it is possible to force the usage of the previous OBITools format.\n\n--output-OBI-header|-O output FASTA/FASTQ title line annotations follow OBI format. (default: false)\n--output-json-header output FASTA/FASTQ title line annotations follow json format. (default: false)"
  },
  {
    "objectID": "common_options.html#helpful-options",
    "href": "common_options.html#helpful-options",
    "title": "6  Options common to most of the OBITools commands",
    "section": "6.1 Helpful options",
    "text": "6.1 Helpful options\n\n--help, -h\n\nDisplay a friendly help message.\n\n\n--no-progressbar"
  },
  {
    "objectID": "common_options.html#system-related-options",
    "href": "common_options.html#system-related-options",
    "title": "6  Options common to most of the OBITools commands",
    "section": "6.2 System related options",
    "text": "6.2 System related options\nManaging parallel execution of tasks\nA new feature of OBITools V4 is the ability to run multiple tasks in parallel, reading files, calculating on the data, formatting and writing the results. Each of these tasks can itself be parallelized by dividing the data into batches and running the calculation on several batches in parallel. This allows the overall calculation time of an OBITools command to be reduced considerably. The parameters organizing the parallel calculation are determined automatically to use the maximum capacity of your computer. But in some circumstances, it is necessary to override these default settings either to try to optimize the computation on a given machine, or to limit the OBITools to using only a part of the computational capacity. There are two options for doing this.\n\n--max-cpu\n\nOBITools V4 are able to run in parallel on all the CPU cores available on the computer. It is sometime required to limit the computation to a smaller number of cores. That option specify the maximum number of cores that the OBITools command can use. This behaviour can also be set up using the OBIMAXCPU environment variable.\n\n\n--workers, -w\nIf your computer has 8 cores, but you want to limit OBITools to use only two of them you have several solution:\n\nIf you want to set the limit for a single execution you can use the –max-cpu option\nobiconvert --max-cpu 2 --fasta-output data.fastq > data.fasta\nor you can precede the command by setting the environment variable OBIMAXCPU\nOBIMAXCPU=2 obiconvert --fasta-output data.fastq > data.fasta\nIf you want to set the limit to your complete session, you have to export OBIMAXCPU\nexport OBIMAXCPU=2 \nall the following OBITools commands will be limited to use at max 2 CPU cores.\nIf all the time you want to impose this limit, you must include the above export command in your .bashrc file.\n\nOBITools debuging related options\n--debug"
  },
  {
    "objectID": "expressions.html#variables-usable-in-the-expression",
    "href": "expressions.html#variables-usable-in-the-expression",
    "title": "7  OBITools expression language",
    "section": "7.1 Variables usable in the expression",
    "text": "7.1 Variables usable in the expression\n\nsequence is the sequence object on which the expression is evaluated.\nannotationsis a map object containing every annotations associated to the currently processed sequence."
  },
  {
    "objectID": "expressions.html#function-defined-in-the-language",
    "href": "expressions.html#function-defined-in-the-language",
    "title": "7  OBITools expression language",
    "section": "7.2 Function defined in the language",
    "text": "7.2 Function defined in the language\n\nInstrospection functions\n\nlen(x)is a generic function allowing to retreive the size of a object. It returns the length of a sequences, the number of element in a map like annotations, the number of elements in an array. The reurned value is an int.\n\n\n\nCast functions\n\nint(x) converts if possible the x value to an integer value. The function returns an int.\nnumeric(x) converts if possible the x value to a float value. The function returns a float.\nbool(x) converts if possible the x value to a boolean value. The function returns a bool.\n\n\n\nString related functions\n\nprintf(format,...) allows to combine several values to build a string. format follows the classical C printf syntax. The function returns a string.\nsubspc(x) substitutes every space in the x string by the underscore (_) character. The function returns a string."
  },
  {
    "objectID": "expressions.html#accessing-to-the-sequence-annotations",
    "href": "expressions.html#accessing-to-the-sequence-annotations",
    "title": "7  OBITools expression language",
    "section": "7.3 Accessing to the sequence annotations",
    "text": "7.3 Accessing to the sequence annotations\nThe annotations variable is a map object containing all the annotations associated to the currently processed sequence. Index of the map are the attribute names. It exists to possibillities to retreive an annotation. It is possible to use the classical [] indexing operator, putting the attribute name quoted by double quotes between them.\nannotations[\"direction\"]\nThe above code retreives the direction annotation. A second notation using the dot (.) is often more convenient.\nannotations.direction\nSpecial attributes of the sequence are accessible only by dedicated methods of the sequence object.\n\nThe sequence identifier : Id()\nTHe sequence definition : Definition()"
  },
  {
    "objectID": "comm_metabarcode_design.html#obipcr",
    "href": "comm_metabarcode_design.html#obipcr",
    "title": "8  Metabarcode design and quality assessment",
    "section": "8.1 obipcr",
    "text": "8.1 obipcr\n\nReplace the ecoPCR original OBITools"
  },
  {
    "objectID": "comm_reformat.html#obiconvert",
    "href": "comm_reformat.html#obiconvert",
    "title": "9  File format conversions",
    "section": "9.1 obiconvert",
    "text": "9.1 obiconvert"
  },
  {
    "objectID": "comm_annotation.html#obiannotate",
    "href": "comm_annotation.html#obiannotate",
    "title": "10  Sequence annotations",
    "section": "10.1 obiannotate",
    "text": "10.1 obiannotate"
  },
  {
    "objectID": "comm_annotation.html#obitag",
    "href": "comm_annotation.html#obitag",
    "title": "10  Sequence annotations",
    "section": "10.2 obitag",
    "text": "10.2 obitag"
  },
  {
    "objectID": "comm_computation.html#obipairing",
    "href": "comm_computation.html#obipairing",
    "title": "11  Computations on sequences",
    "section": "11.1 obipairing",
    "text": "11.1 obipairing\n\nReplace the illuminapairedends original OBITools\n\n\nAlignment procedure\nobipairing is introducing a new alignment algorithm compared to the illuminapairedend command of the OBITools V2. Nethertheless this new algorithm has been design to produce the same results than the previous, except in very few cases.\nThe new algorithm is a two-step procedure. First, a FASTN-type algorithm (Lipman and Pearson 1985) identifies the best offset between the two matched readings. This identifies the region of overlap.\nIn the second step, the matching regions of the two reads are extracted along with a flanking sequence of \\(\\Delta\\) base pairs. The two subsequences are then aligned using a “one side free end-gap” dynamic programming algorithm. This latter step is only called if at least one mismatch is detected by the FASTP step.\nUnless the similarity between the two reads at their overlap region is very low, the addition of the flanking regions in the second step of the alignment ensures the same alignment as if the dynamic programming alignment was performed on the full reads.\n\n\nThe scoring system\nIn the dynamic programming step, the match and mismatch scores take into account the quality scores of the two aligned nucleotides. By taking these into account, the probability of a true match can be calculated for each aligned base pair.\nIf we consider a nucleotide read with a quality score \\(Q\\), the probability of misreading this base (\\(P_E\\)) is : \\[\nP_E = 10^{-\\frac{Q}{10}}\n\\]\nThus, when a given nucleotide \\(X\\) is observed with the quality score \\(Q\\). The probability that \\(X\\) is really an \\(X\\) is :\n\\[\nP(X=X) = 1 - P_E\n\\]\nOtherwise, \\(X\\) is actually one of the three other possible nucleotides (\\(X_{E1}\\), \\(X_{E2}\\) or \\(X_{E3}\\)). If we suppose that the three reading error have the same probability :\n\\[\nP(X=X_{E1}) = P(X=X_{E3}) = P(X=X_{E3}) = \\frac{P_E}{3}\n\\]\nAt each position in an alignment where the two nucleotides \\(X_1\\) and \\(X_2\\) face each other (not a gapped position), the probability of a true match varies depending on whether \\(X_1=X_2\\), an observed match, or \\(X_1 \\neq X_2\\), an observed mismatch.\nProbability of a true match when \\(X_1=X_2\\)\nThat probability can be divided in two parts. First \\(X_1\\) and \\(X_2\\) have been correctly read. The corresponding probability is :\n\\[\n\\begin{aligned}\nP_{TM} &= (1- PE_1)(1-PE_2)\\\\\n       &=(1 - 10^{-\\frac{Q_1}{10} } )(1 - 10^{-\\frac{Q_2}{10}} )\n\\end{aligned}\n\\]\nSecondly, a match can occure if the true nucleotides read as \\(X_1\\) and \\(X_2\\) are not \\(X_1\\) and \\(X_2\\) but identical.\n\\[\n\\begin{aligned}\nP(X_1==X_{E1}) \\cap P(X_2==X_{E1}) &= \\frac{P_{E1} P_{E2}}{9} \\\\\nP(X_1==X_{Ex}) \\cap P(X_2==X_{Ex}) & = \\frac{P_{E1} P_{E2}}{3}\n\\end{aligned}\n\\]\nThe probability of a true match between \\(X_1\\) and \\(X_2\\) when \\(X_1 = X_2\\) an observed match :\n\\[\n\\begin{aligned}\nP(MATCH | X_1 = X_2) = (1- PE_1)(1-PE_2) + \\frac{P_{E1} P_{E2}}{3}\n\\end{aligned}\n\\]\nProbability of a true match when \\(X_1 \\neq X_2\\)\nThat probability can be divided in three parts.\n\n\\(X_1\\) has been correctly read and \\(X_2\\) is a sequencing error and is actually equal to \\(X_1\\). \\[\nP_a =  (1-P_{E1})\\frac{P_{E2}}{3}\n\\]\n\\(X_2\\) has been correctly read and \\(X_1\\) is a sequencing error and is actually equal to \\(X_2\\). \\[\nP_b =  (1-P_{E2})\\frac{P_{E1}}{3}\n\\]\n\\(X_1\\) and \\(X_2\\) corresponds to sequencing error but are actually the same base \\(X_{Ex}\\) \\[\nP_c = 2\\frac{P_{E1} P_{E2}}{9}\n\\]\n\nConsequently : \\[\n\\begin{aligned}\nP(MATCH | X_1 \\neq X_2) =  (1-P_{E1})\\frac{P_{E2}}{3} +  (1-P_{E2})\\frac{P_{E1}}{3} + 2\\frac{P_{E1} P_{E2}}{9}\n\\end{aligned}\n\\]\nProbability of a match under the random model\nThe second considered model is a pure random model where every base is equiprobable, hence having a probability of occurrence of a nucleotide equals \\(0.25\\). Under that hypothesis\n\\[\nP(MATCH | \\text{Random model}) = 0.25\n\\]\nThe score is a log ration of likelyhood\nScore is define as the logarithm of the ratio between the likelyhood of the observations considering the sequencer error model over tha likelyhood u\n\n\n\n\n\nEvolution of the match and mismatch scores when the quality of base is 20 while the second range from 10 to 40."
  },
  {
    "objectID": "comm_computation.html#obimultiplex",
    "href": "comm_computation.html#obimultiplex",
    "title": "11  Computations on sequences",
    "section": "11.2 obimultiplex",
    "text": "11.2 obimultiplex\n\nReplace the ngsfilter original OBITools"
  },
  {
    "objectID": "comm_computation.html#obicomplement",
    "href": "comm_computation.html#obicomplement",
    "title": "11  Computations on sequences",
    "section": "11.3 obicomplement",
    "text": "11.3 obicomplement"
  },
  {
    "objectID": "comm_computation.html#obiclean",
    "href": "comm_computation.html#obiclean",
    "title": "11  Computations on sequences",
    "section": "11.4 obiclean",
    "text": "11.4 obiclean"
  },
  {
    "objectID": "comm_computation.html#obiuniq",
    "href": "comm_computation.html#obiuniq",
    "title": "11  Computations on sequences",
    "section": "11.5 obiuniq",
    "text": "11.5 obiuniq\n\n\n\n\nLipman, D J, and W R Pearson. 1985. “Rapid and sensitive protein similarity searches.” Science 227 (4693): 1435–41. http://www.ncbi.nlm.nih.gov/pubmed/2983426."
  },
  {
    "objectID": "comm_sampling.html#obigrep-filters-sequence-files-according-to-numerous-conditions",
    "href": "comm_sampling.html#obigrep-filters-sequence-files-according-to-numerous-conditions",
    "title": "12  Sequence sampling and filtering",
    "section": "12.1 obigrep – filters sequence files according to numerous conditions",
    "text": "12.1 obigrep – filters sequence files according to numerous conditions\nThe obigrep command is somewhat analogous to the standard Unix grep command. It selects a subset of sequence records from a sequence file. A sequence record is a complex object consisting of an identifier, a set of attributes (a key, defined by its name, associated with a value), a definition, and the sequence itself. Instead of working text line by text line like the standard Unix tool, obigrep selection is done sequence record by sequence record. A large number of options allow you to refine the selection on any element of the sequence. obigrep allows you to specify multiple conditions simultaneously (which take on the value TRUE or FALSE) and only those sequence records which meet all conditions (all conditions are TRUE) are selected. obigrep is able to work on two paired read files. The selection criteria apply to one or the other of the readings in each pair depending on the mode chosen (--paired-mode option). In all cases the selection is applied in the same way to both files, thus maintaining their consistency.\n\n12.1.1 The options usable with obigrep\n\n12.1.1.1 Selecting sequences based on their caracteristics\nSequences can be selected on several of their caracteristics, their length, their id, their sequence. Options allow for specifying the condition if selection.\n\n--min-count | -c COUNT\n\nonly sequences reprensenting at least COUNT reads will be selected. That option rely on the count attribute. If the count attribute is not defined for a sequence record, it is assumed equal to \\(1\\).\n\n--max-count | -C COUNT\n\nonly sequences reprensenting no more than COUNT reads will be selected. That option rely on the count attribute. If the count attribute is not defined for a sequence record, it is assumed equal to \\(1\\).\n\nExample\n\nSelecting sequence records representing at least five reads in the dataset.\n\n\nobigrep -c 5 data_SPER01.fasta > data_norare_SPER01.fasta"
  },
  {
    "objectID": "comm_utilities.html#obicount",
    "href": "comm_utilities.html#obicount",
    "title": "13  Utilities",
    "section": "13.1 obicount",
    "text": "13.1 obicount\nobicount counts the number of sequence records, the sum of the count attributes, and the sum of the length of all the sequences.\nExample:\nobicount seq.fasta  \nPrints the number of sequence records contained in the seq.fasta file and the sum of their count attributes.\nOptions specific to the command\n\n--reads|-r Prints read counts.\n--symbols|-s Prints symbol counts.\n--variants|-v Prints variant counts."
  },
  {
    "objectID": "comm_utilities.html#obidistribute",
    "href": "comm_utilities.html#obidistribute",
    "title": "13  Utilities",
    "section": "13.2 obidistribute",
    "text": "13.2 obidistribute"
  },
  {
    "objectID": "comm_utilities.html#obifind",
    "href": "comm_utilities.html#obifind",
    "title": "13  Utilities",
    "section": "13.3 obifind",
    "text": "13.3 obifind\n\nReplace the ecofind original OBITools."
  },
  {
    "objectID": "library.html#biosequence",
    "href": "library.html#biosequence",
    "title": "The GO OBITools library",
    "section": "BioSequence",
    "text": "BioSequence\nThe BioSequence class is used to represent biological sequences. It allows for storing : - the sequence itself as a []byte - the sequencing quality score as a []byte if needed - an identifier as a string - a definition as a string - a set of (key, value) pairs in a map[sting]interface{}\nBioSequence is defined in the obiseq module and is included using the code\nimport (\n    \"git.metabarcoding.org/lecasofts/go/obitools/pkg/obiseq\"\n)\n\nCreating new instances\nTo create new instance, use\n\nMakeBioSequence(id string, sequence []byte, definition string) obiseq.BioSequence\nNewBioSequence(id string, sequence []byte, definition string) *obiseq.BioSequence\n\nBoth create a BioSequence instance, but when the first one returns the instance, the second returns a pointer on the new instance. Two other functions MakeEmptyBioSequence, and NewEmptyBioSequence do the same job but provide an uninitialized objects.\n\nid parameters corresponds to the unique identifier of the sequence. It mist be a string constituted of a single word (not containing any space).\nsequence is the DNA sequence itself, provided as a byte array ([]byte).\ndefinition is a string, potentially empty, but usualy containing a sentence explaining what is that sequence.\n\nimport (\n    \"git.metabarcoding.org/lecasofts/go/obitools/pkg/obiseq\"\n)\n\nfunc main() {\n    myseq := obiseq.NewBiosequence(\n        \"seq_GH0001\",\n        bytes.FromString(\"ACGTGTCAGTCG\"),\n        \"A short test sequence\",\n        )\n}\nWhen formated as fasta the parameters correspond to the following schema\n>id definition containing potentially several words\nsequence\n\n\nEnd of life of a BioSequence instance\nWhen an instance of BioSequence is no longer in use, it is normally taken over by the GO garbage collector. If you know that an instance will never be used again, you can, if you wish, call the Recycle method on it to store the allocated memory elements in a pool to limit the allocation effort when many sequences are being handled. Once the recycle method has been called on an instance, you must ensure that no other method is called on it.\n\n\nAccessing to the elements of a sequence\nThe different elements of an obiseq.BioSequence must be accessed using a set of methods. For the three main elements provided during the creation of a new instance methodes are :\n\nId() string\nSequence() []byte\nDefinition() string\n\nIt exists pending method to change the value of these elements\n\nSetId(id string)\nSetSequence(sequence []byte)\nSetDefinition(definition string)\n\nimport (\n    \"fmt\"\n    \"git.metabarcoding.org/lecasofts/go/obitools/pkg/obiseq\"\n)\n\nfunc main() {\n    myseq := obiseq.NewBiosequence(\n        \"seq_GH0001\",\n        bytes.FromString(\"ACGTGTCAGTCG\"),\n        \"A short test sequence\",\n        )\n\n    fmt.Println(myseq.Id())\n    myseq.SetId(\"SPE01_0001\")\n    fmt.Println(myseq.Id())\n}\n\nDifferent ways for accessing an editing the sequence\nIf Sequence()and SetSequence(sequence []byte) methods are the basic ones, several other methods exist.\n\nString() string return the sequence directly converted to a string instance.\nThe Write method family allows for extending an existing sequence following the buffer protocol.\n\nWrite(data []byte) (int, error) allows for appending a byte array on 3’ end of the sequence.\nWriteString(data string) (int, error) allows for appending a string.\nWriteByte(data byte) error allows for appending a single byte.\n\n\nThe Clear method empties the sequence buffer.\nimport (\n    \"fmt\"\n    \"git.metabarcoding.org/lecasofts/go/obitools/pkg/obiseq\"\n)\n\nfunc main() {\n    myseq := obiseq.NewEmptyBiosequence()\n\n    myseq.WriteString(\"accc\")\n    myseq.WriteByte(byte('c'))\n    fmt.Println(myseq.String())\n}\n\n\nSequence quality scores\nSequence quality scores cannot be initialized at the time of instance creation. You must use dedicated methods to add quality scores to a sequence.\nTo be coherent the length of both the DNA sequence and que quality score sequence must be equal. But assessment of this constraint is realized. It is of the programmer responsability to check that invariant.\nWhile accessing to the quality scores relies on the method Quality() []byte, setting the quality need to call one of the following method. They run similarly to their sequence dedicated conterpart.\n\nSetQualities(qualities Quality)\nWriteQualities(data []byte) (int, error)\nWriteByteQualities(data byte) error\n\nIn a way analogous to the Clear method, ClearQualities() empties the sequence of quality scores.\n\n\n\nThe annotations of a sequence\nA sequence can be annotated with attributes. Each attribute is associated with a value. An attribute is identified by its name. The name of an attribute consists of a character string containing no spaces or blank characters. Values can be of several types.\n\nScalar types:\n\ninteger\nnumeric\ncharacter\nboolean\n\nContainer types:\n\nvector\nmap\n\n\nVectors can contain any type of scalar. Maps are compulsorily indexed by strings and can contain any scalar type. It is not possible to have nested container type.\nAnnotations are stored in an object of type bioseq.Annotation which is an alias of map[string]interface{}. This map can be retrieved using the Annotations() Annotation method. If no annotation has been defined for this sequence, the method returns an empty map. It is possible to test an instance of BioSequence using its HasAnnotation() bool method to see if it has any annotations associated with it.\n\nGetAttribute(key string) (interface{}, bool)"
  },
  {
    "objectID": "library.html#the-sequence-iterator",
    "href": "library.html#the-sequence-iterator",
    "title": "The GO OBITools library",
    "section": "The sequence iterator",
    "text": "The sequence iterator\nThe pakage obiter provides an iterator mecanism for manipulating sequences. The main class provided by this package is obiiter.IBioSequence. An IBioSequence iterator provides batch of sequences.\n\nBasic usage of a sequence iterator\nMany functions, among them functions reading sequences from a text file, return a IBioSequence iterator. The iterator class provides two main methods:\n\nNext() bool\nGet() obiiter.BioSequenceBatch\n\nThe Next method moves the iterator to the next value, while the Get method returns the currently pointed value. Using them, it is possible to loop over the data as in the following code chunk.\nimport (\n    \"git.metabarcoding.org/lecasofts/go/obitools/pkg/obiformats\"\n)\n\nfunc main() {\n    mydata := obiformats.ReadFastSeqFromFile(\"myfile.fasta\")\n       \n    for mydata.Next() {\n        data := mydata.Get()\n        //\n        // Whatever you want to do with the data chunk\n        //\n    }\n}\nAn obiseq.BioSequenceBatch instance is a set of sequences stored in an obiseq.BioSequenceSlice and a sequence number. The number of sequences in a batch is not defined. A batch can even contain zero sequences, if for example all sequences initially included in the batch have been filtered out at some stage of their processing.\n\n\nThe Pipable functions\nA function consuming a obiiter.IBioSequence and returning a obiiter.IBioSequence is of class obiiter.Pipable.\n\n\nThe Teeable functions\nA function consuming a obiiter.IBioSequence and returning two obiiter.IBioSequence instance is of class obiiter.Teeable."
  },
  {
    "objectID": "annexes.html",
    "href": "annexes.html",
    "title": "Appendix A — Annexes",
    "section": "",
    "text": "A.0.1 Sequence attributes\n\nA.0.1.1 Reserved sequence attributes\n\nA.0.1.1.1 ali_dir\n\nA.0.1.1.1.1 Type : string\nThe attribute can contain 2 string values \"left\" or \"right\".\n\n\nA.0.1.1.1.2 Set by the obipairing tool\nThe alignment generated by obipairing is a 3’-end gap free algorithm. Two cases can occur when aligning the forward and reverse reads. If the barcode is long enough, both the reads overlap only on their 3’ ends. In such case, the alignment direction ali_dir is set to left. If the barcode is shorter than the read length, the paired reads overlap by their 5’ ends, and the complete barcode is sequenced by both the reads. In that later case, ali_dir is set to right.\n\n\n\nA.0.1.1.2 ali_length\n\nA.0.1.1.2.1 Set by the obipairing tool\nLength of the aligned parts when merging forward and reverse reads\n\n\n\nA.0.1.1.3 count : the number of sequence occurrences\n\nA.0.1.1.3.1 Set by the obiuniq tool\nThe count attribute indicates how-many strictly identical sequences have been merged in a single record. It contains an integer value. If it is absent this means that the sequence record represents a single occurrence of the sequence.\n\n\nA.0.1.1.3.2 Getter : method Count()\nThe Count() method allows to access to the count attribute as an integer value. If the count attribute is not defined for the given sequence, the value 1 is returned\n\n\n\nA.0.1.1.4 merged_*\n\nA.0.1.1.4.1 Type : map[string]int\n\n\nA.0.1.1.4.2 Set by the obiuniq tool\nThe -m option of the obiuniq tools allows for keeping track of the distribution of the values stored in given attribute of interest. Often this option is used to summarise distribution of a sequence variant accross samples when obiuniq is run after running obimultiplex. The actual name of the attribute depends on the name of the monitored attribute. If -m option is used with the attribute sample, then this attribute names merged_sample.\n\n\n\nA.0.1.1.5 mode\n\nA.0.1.1.5.1 Set by the obipairing tool\nobitag_ref_index\n\n\nA.0.1.1.5.2 Set by the obirefidx tool.\nIt resumes to which taxonomic annotation a match to that sequence must lead according to the number of differences existing between the query sequence and the reference sequence having that tag.\n\n\nA.0.1.1.5.3 Getter : method Count()\n\n\n\nA.0.1.1.6 pairing_mismatches\n\nA.0.1.1.6.1 Set by the obipairing tool\n\n\n\nA.0.1.1.7 score\n\nA.0.1.1.7.1 Set by the obipairing tool\n\n\n\nA.0.1.1.8 score_norm\n\nA.0.1.1.8.1 Set by the obipairing tool"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Andersen, Kenneth, Karen Lise Bird, Morten Rasmussen, James Haile,\nHenrik Breuning-Madsen, Kurt H Kjaer, Ludovic Orlando, M Thomas P\nGilbert, and Eske Willerslev. 2012. “Meta-barcoding of ëdirtı́DNA from soil reflects vertebrate\nbiodiversity.” Molecular Ecology 21 (8): 1966–79.\n\n\nBaldwin, Darren S, Matthew J Colloff, Gavin N Rees, Anthony A Chariton,\nGarth O Watson, Leon N Court, Diana M Hartley, et al. 2013. “Impacts of inundation and drought on eukaryote\nbiodiversity in semi-arid floodplain soils.” Molecular\nEcology 22 (6): 1746–58. https://doi.org/10.1111/mec.12190.\n\n\nBoyer, Frédéric, Céline Mercier, Aurélie Bonin, Yvan Le Bras, Pierre\nTaberlet, and Eric Coissac. 2016. “obitools:\na unix-inspired software package for DNA metabarcoding.”\nMolecular Ecology Resources 16 (1): 176–82. https://doi.org/10.1111/1755-0998.12428.\n\n\nCaporaso, J Gregory, Justin Kuczynski, Jesse Stombaugh, Kyle Bittinger,\nFrederic D Bushman, Elizabeth K Costello, Noah Fierer, et al. 2010.\n“QIIME allows analysis of high-throughput\ncommunity sequencing data.” Nature Methods 7 (5):\n335–36. https://doi.org/10.1038/nmeth.f.303.\n\n\nChariton, Anthony A, Anthony C Roach, Stuart L Simpson, and Graeme E\nBatley. 2010. “Influence of the choice of\nphysical and chemistry variables on interpreting patterns of sediment\ncontaminants and their relationships with estuarine macrobenthic\ncommunities.” Marine and Freshwater Research. https://doi.org/10.1071/mf09263.\n\n\nCock, Peter JA, Christopher J Fields, Naohisa Goto, Michael L Heuer, and\nPeter M Rice. 2010. “The Sanger FASTQ File Format for Sequences\nwith Quality Scores, and the Solexa/Illumina FASTQ Variants.”\nNucleic Acids Research 38 (6): 1767–71.\n\n\nDeagle, Bruce E, Roger Kirkwood, and Simon N Jarman. 2009. “Analysis of Australian fur seal diet by pyrosequencing\nprey DNA in faeces.” Molecular Ecology 18 (9):\n2022–38. https://doi.org/10.1111/j.1365-294X.2009.04158.x.\n\n\nKowalczyk, Rafał, Pierre Taberlet, Eric Coissac, Alice Valentini,\nChristian Miquel, Tomasz Kamiński, and Jan M Wójcik. 2011. “Influence of management practices on large herbivore\ndiet—Case of European bison in Białowieża Primeval Forest (Poland).”\nForest Ecology and Management 261 (4): 821–28. https://doi.org/10.1016/j.foreco.2010.11.026.\n\n\nLipman, D J, and W R Pearson. 1985. “Rapid\nand sensitive protein similarity searches.”\nScience 227 (4693): 1435–41. http://www.ncbi.nlm.nih.gov/pubmed/2983426.\n\n\nParducci, Laura, Tina Jørgensen, Mari Mette Tollefsrud, Ellen Elverland,\nTorbjørn Alm, Sonia L Fontana, K D Bennett, et al. 2012. “Glacial survival of boreal trees in northern\nScandinavia.” Science 335 (6072): 1083–86. https://doi.org/10.1126/science.1216043.\n\n\nRiaz, Tiayyba, Wasim Shehzad, Alain Viari, François Pompanon, Pierre\nTaberlet, and Eric Coissac. 2011. “ecoPrimers: inference of new DNA barcode markers from\nwhole genome sequence analysis.” Nucleic Acids\nResearch 39 (21): e145. https://doi.org/10.1093/nar/gkr732.\n\n\nSchloss, Patrick D, Sarah L Westcott, Thomas Ryabin, Justine R Hall,\nMartin Hartmann, Emily B Hollister, Ryan A Lesniewski, et al. 2009.\n“Introducing mothur: open-source,\nplatform-independent, community-supported software for describing and\ncomparing microbial communities.” Applied and\nEnvironmental Microbiology 75 (23): 7537–41. https://doi.org/10.1128/AEM.01541-09.\n\n\nSeguritan, V, and F Rohwer. 2001. “FastGroup:\na program to dereplicate libraries of 16S rDNA sequences.”\nBMC Bioinformatics 2 (October): 9. https://doi.org/10.1186/1471-2105-2-9.\n\n\nShehzad, Wasim, Tiayyba Riaz, Muhammad A Nawaz, Christian Miquel, Carole\nPoillot, Safdar A Shah, Francois Pompanon, Eric Coissac, and Pierre\nTaberlet. 2012. “Carnivore diet analysis\nbased on next-generation sequencing: Application to the leopard cat\n(Prionailurus bengalensis) in Pakistan.” Molecular\nEcology 21 (8): 1951–65. https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-294X.2011.05424.x.\n\n\nSogin, Mitchell L, Hilary G Morrison, Julie A Huber, David Mark Welch,\nSusan M Huse, Phillip R Neal, Jesus M Arrieta, and Gerhard J Herndl.\n2006. “Microbial diversity in the deep sea\nand the underexplored \"rare biosphere\".” Proceedings\nof the National Academy of Sciences of the United States of America\n103 (32): 12115–20. https://doi.org/10.1073/pnas.0605127103.\n\n\nSønstebø, J H, L Gielly, A K Brysting, R Elven, M Edwards, J Haile, E\nWillerslev, et al. 2010. “Using\nnext-generation sequencing for molecular reconstruction of past Arctic\nvegetation and climate.” Molecular Ecology\nResources 10 (6): 1009–18. https://doi.org/10.1111/j.1755-0998.2010.02855.x.\n\n\nTaberlet, Pierre, Eric Coissac, Mehrdad Hajibabaei, and Loren H\nRieseberg. 2012. “Environmental DNA.”\nMolecular Ecology 21 (8): 1789–93. https://doi.org/10.1111/j.1365-294X.2012.05542.x.\n\n\nThomsen, Philip Francis, Jos Kielgast, Lars L Iversen, Carsten Wiuf,\nMorten Rasmussen, M Thomas P Gilbert, Ludovic Orlando, and Eske\nWillerslev. 2012. “Monitoring endangered\nfreshwater biodiversity using environmental DNA.”\nMolecular Ecology 21 (11): 2565–73. https://doi.org/10.1111/j.1365-294X.2011.05418.x.\n\n\nValentini, Alice, Christian Miquel, Muhammad Ali Nawaz, Eva Bellemain,\nEric Coissac, François Pompanon, Ludovic Gielly, et al. 2009.\n“New perspectives in diet analysis based on\nDNA barcoding and parallel pyrosequencing: the trnL\napproach.” Molecular Ecology Resources 9 (1):\n51–60. https://doi.org/10.1111/j.1755-0998.2008.02352.x.\n\n\nYoccoz, N G, K A Bråthen, L Gielly, J Haile, M E Edwards, T Goslar, H\nVon Stedingk, et al. 2012. “DNA from soil\nmirrors plant taxonomic and growth form diversity.”\nMolecular Ecology 21 (15): 3647–55. https://doi.org/10.1111/j.1365-294X.2012.05545.x."
  }
]